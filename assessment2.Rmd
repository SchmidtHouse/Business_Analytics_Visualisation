---
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## *Christopher Schmidt* 
## **S4532362**
******
# Assessment 2 
******

```{r}
## install packages once via console using - install.packages("tidyverse")
library(tidyverse)   # load tidyverse library
library(skimr)       # load skimr library
library(janitor)     # load janitor library
library(ggplot2)     # load ggplot library
library(knitr)       # load knitr library
library(randomForest)# load randomForest library 

```

### Insert an R chunk and create a dataset variable called `data`

```{r}
# use readr function to import the and read data from csv
# save data into dataset called "data"
data <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2018/2018-11-20/thanksgiving_meals.csv')
```

### Part 2: Data Wrangling and visualization 

### 1. Display the first 10 rows of the dataset using `kable()` function

```{r}
# use kable function to read dataset and display first 10 rows and the first 5 variables
kable((data[1:10, 1:5])) 
```

### 2. Using `skim()` display the summary of variables

#### **Main observations:** 
* Data missing from most variables and will need to be removed before using in later and calculations and visualizations
* There are a large number of side, pie and dessert variables

```{r}
# pipe dataset into skim function to summarize whole dataset
data %>% 
  skim() 
```

### 3. Use `fct_reorder` and `parse_number` functions to create a factor variable `family_income`

```{r}
# Pipe dataset into mutate and use fct_reorder to reorder factor levels by sorting with variable family_income and save back to dataset
# Use parse_number function to drop any non-numeric characters before or after the first number in variable family_income
data <- data %>%
  mutate(family_income = fct_reorder(family_income, parse_number(family_income, na = c("Prefer not to answer")))) 
```

### 4. What is the number of people who celebrate?

#### **Main observations:** 
* 980 people celebrate thanksgiving

```{r}
# Pipe dataset into count function and count variable celebrate (total how many yes / no answers) then
# pipe into arrange function and arrange rows by variables celebrate in descending order then
# pipe into kabble() function to create simple table with output
data %>% 
  count(celebrate) %>% 
  arrange(-n) %>%
  kable()
```

### 5. What are categories and insights for each main dish served and the method it is prepared?

#### **Main observations:** 
* Main dish categories include: Turkey, Ham/Pork, Roast beef, Tofurkey, Chicken, Turducken and Other/I dont know.
* Main prep categories include: Baked, Roasted, Fried and Other/I dont know.

```{r}
# pipe dataset into filter function and remove all na obs from variable main_dish and main_prep then
# pipe into group_by function and select variable main_dish, main_prep and main_prep_other then
# pipe into count function and count variable main_dish and sort in descending order then
# pipe into kabble() function to create simple table with output
data %>%
  filter(!is.na(main_dish) & !is.na(main_prep)) %>%
  group_by(main_dish, main_prep, main_prep_other) %>%
  count(main_dish, sort=TRUE) %>%
  kable()
```

### 6. Create 3 different data viz showing insights for main dish served and the method.

#### **Data visualisation 1** 
* Shows the most prevalent main dish's served according to most prevalent preparation methods
* Most prevalent dish's served on thanksgiving are: 
1. Turkey 
2. Ham/Pork 
3. Other 
4. Tofurkey 
5. Roast beef 
6. Chicken

```{r}
# Data visualisation 1
# pipe dataset into filter function and remove all na obs from variable main_dish then
# pipe into mutate, select var main_dish and use fct_collapse to collapse 3 x obs into manually defined group "Other" then
# pipe into mutate, select var main_prep and use fct_collapse to collapse 3 x obs into manually defined group "Other" then
# pipe into ggplot, select discrete variable main_prep and use variable main_prep as color and fill in data viz then
# add geom_bar and use facet_wrap to create 4 plots for variable main_dish and allow x scale to vary across rows then
# add a label to the x axis and use coord_flip so that horizontal becomes vertical, and vertical, horizontal then
# add theme "theme_minimal" which controls all non-data display
data %>% 
  filter(!is.na(main_dish) & !is.na(main_prep)) %>%
  mutate(main_dish = fct_collapse(main_dish, Other = c("I don't know", "Other (please specify)", "Turducken"))) %>%
  mutate(main_prep = fct_collapse(main_prep, Other = c("I don't know", "Other (please specify)"))) %>%
  ggplot(aes(main_prep, color=main_prep,fill = main_prep))+ 
  geom_bar()+ # add Bar charts using geom_bar
  facet_wrap(vars(main_dish), ncol = 3, scales = "free_x")+ 
  labs(x = "Method")+
  coord_flip() +
  theme_minimal()
```

#### ***Data visualisation 2***
* Shows the most prevalent preparation methods according to dish served
* Most prevalent preparation methods on thanksgiving are:
1. Baked 
2. Roasted
3. Other 
4. Fried

```{r}
# Data visualisation 2
# pipe dataset into filter function and remove all na obs from variable main_dish then
# pipe into mutate, select var main_dish and use fct_collapse to collapse 3 x obs into manually defined group "Other" then
# pipe into mutate, select var main_prep and use fct_collapse to collapse 3 x obs into manually defined group "Other" then
# pipe into ggplot, select discrete variable main_prep and use variable main_prep as color and fill in data viz then
# add geom_bar and use facet_wrap to create 2 plots for variable main_prep and allow x scale to vary across rows then
# add a label to the x axis and use coord_flip so that horizontal becomes vertical, and vertical, horizontal then
# add theme "theme_minimal" which controls all non-data display
data %>%
  filter(!is.na(main_dish) & !is.na(main_prep)) %>%
  mutate(main_dish = fct_collapse(main_dish, Other = c("I don't know", "Other (please specify)", "Turducken"))) %>%
  mutate(main_prep = fct_collapse(main_prep, Other = c("I don't know", "Other (please specify)"))) %>%
  ggplot(aes(main_dish,color=main_dish,fill = main_dish))+
  geom_bar()+
  facet_wrap(vars(main_prep), ncol = 2, scales = "free_x") +
  labs(x = "Dish served") +
  coord_flip()+
  theme_minimal()
```

#### ***Data visualisation 3*** 
* Shows the most prevalent preparation methods for Turkey by count
* Most prevalent preparation methods for Turkey are:
1. Baked 
2. Roasted 
3. Other

```{r}
# Data viz 3
# pipe dataset into filter function and remove all na obs from variable main_dish and main_prep then
# pipe into mutate, select main_dish, use fct_lump to lumps together the least frequent levels, ensuring that "other" is still the smallest
# pipe into mutate, select var main_prep, use fct_lump to lumps together the least frequent levels, ensuring that "other" is still the smallest
# pipe into ggplot, select discrete variable main_dish and use variable main_dish as color and fill in data viz then
# add geom_bar and use facet_wrap to create 3 plots for variable main_prep then
# add a label to the x axis and use theme function to remove legend then
# add theme "theme_minimal" which controls all non-data display
data %>%
  filter(!is.na(main_dish) & !is.na(main_prep)) %>%
  mutate(main_dish = fct_lump_lowfreq(main_dish)) %>% # Use fct_lump to lump together all the small main_dish 
  mutate(main_prep = fct_lump_lowfreq(main_prep)) %>% # Use fct_lump to lump together all the small main_prep 
  ggplot(aes(main_dish,color=main_dish,fill = main_dish))+
  geom_bar()+
  facet_wrap(vars(main_prep), ncol = 3)+
  labs(x = "Dish served") +
  theme(legend.position = "none")+
  theme_minimal()
```


### 7. How many use cranberry sauce? How many use gravy?

#### **Main observations:** 
* 828 people use cranberry
* 892 people use gravy

#### Count of cranberry sauce use

```{r}
# pipe dataset into filter function and remove all na obs from variable main_dish then
# pipe into mutate, select var cranberry and use fct_collapse to collapse 2 x obs into manually defined groups "Yes / No" then
# pipe into count function and count variable cranberry and sort in descending order then
# pipe into kabble() function to create simple table with output
data %>%
  filter(!is.na(main_dish)) %>%
  mutate(cranberry = fct_collapse(cranberry,
                                  Yes = c("Homemade","Canned", "Other (please specify)"),
                                  No = c("None"))) %>%
  count(cranberry, sort = TRUE) %>%
  kable()
```

#### Count of gravy use

```{r}
# pipe dataset into filter function and remove all na obs from variable main_dish then
# pipe into count function and count variable gravy and sort in descending order then
# pipe into kabble() function to create simple table with output
data %>%
  filter(!is.na(main_dish)) %>%
  count(gravy, sort = TRUE) %>%
  kable()
```

### 8. What is the distribution of those who celebrate across income ranges

#### **Main observation:** 
* High and low income earners are less likely to celebrate thanksgiving than middle to low income earners
* The 25K to 124K income range is the most prevalent between people that celebrate thanksgiving

```{r}
# pipe dataset into filter function and select celebrate = yes, remove "prefer not to say" obs from variable family_income then
# pipe into ggplot, select variable family_income and use variable family_income as color and fill in data viz then
# add geom_bar and use labs function to add a label to the x and y axis then 
# use coord_flip so that horizontal becomes vertical, and vertical, horizontal then 
# use theme function to remove legend
# add theme "theme_minimal" which controls all non-data display
data %>%
  filter((celebrate=="Yes") & family_income != "Prefer not to answer") %>% 
  ggplot(aes(family_income,color=family_income,fill = family_income))+
  geom_bar()+
  labs(x = "Income ranges", y = "Distribution") +
  coord_flip()+
  theme(legend.position = "none") +
  theme_minimal()
```

### 10. Use the following code to create a new data 

##### Create new dataset that contans the different groups of type side dish by id

```{r}
# pipe dataset into select function and select id and any obs that stats with side. pie, dessert then
# pipe into select function to remove variables side15, pie13, desert12 then
# pipe into gather function to gather into key-values pairs by id then and create new columns "type" and  "vaule" then
# pipe dataset into filter function and remove all na, "none" and "Other not to say" obs then
# pipe into mutate function and use str_remove function to remove ""\\d+" from type column  
# create new dataset "new_data" to assign output back into 
new_data <- data %>%
  select(id, starts_with("side"),
         starts_with("pie"),
         starts_with("dessert")) %>%
  select(-side15, -pie13, -dessert12) %>%
  gather(type, value, -id) %>%
  filter(!is.na(value),
         !value %in% c("None", "Other (please specify)")) %>%
  mutate(type = str_remove(type, "\\d+"))
```

### 11. Intall package `widyr` and use `pairwise_cor()` function

#### **Main observation:** 
* Cookies and Brownies have the highest correlation (0.41) 

```{r}
# download and install "widyr" package from CRAN repositories then
# install packages once via console using - install.packages("widyr")
# load library "widyr" using library(widyr)
# pipe "new_data" into pairwise_cor function to identify groups of highly correlated items "value and id" and sort in descending order

# install.packages("widyr")
library(widyr)

new_data %>% pairwise_cor(value, id, sort = TRUE)
```

### 13. Use `lm()` or `randomForest()` function to build a model that predict a family income based on data in the dataset.

#### **Main observation:** What America eats on thanksgiving is a poor indicator to predict family income.

1. Model 3 showed the highest relationship (~9%) between age, work and comunity type based variables and family income.
2. Model 2 showed a (~7.5%) relationship between age and location based variables and family income.
3. Model 1 showed a (~6%) relationship between food based variables and family income

##### Remove any non-numeric characters and na obs from variable "family_income" and save to new variable "family_income_num".

```{r}
# pipe dataset into mutate and use parse_number function to drop any non-numeric characters before or after the first number in variable family_income and create new column family_income_num to save output then
# pipe dataset into filter function and remove all na obs from variable family_income_num then
# create new dataset "data1" to assign output back into data1
data1 <- data %>%
  mutate(family_income_num=parse_number(as.character(family_income))) %>%
  filter(!is.na(family_income_num))
```

##### Model 1:  Food based regression model 
* Shows a low relationship (~6%) between food based variables and family income.
* Based on a forest of trees using random inputs from celebrate, main_dish, main_prep, and age.

```{r}
# download and install "randomForest" package from CRAN repositories then
# install packages once via console using - install.packages("randomForest")
# use randomForest function to predict correlation of celebrate, main_dish, main_prep, age to family_income_num and remove "na" obs from data
randomForest(family_income_num~celebrate+main_dish+main_prep+age,data=data1, na.action=na.omit)
```

##### Model 2:  Work and location based regression model 
* Shows a low relationship (~7.5%) between age and location based variables and family income.
* Based on a forest of trees using random inputs from age, community_type, us_region.

```{r}
# use randomForest function to predict correlation of age, community_type and us_region to family_income_num and remove "na" obs from data
randomForest(family_income_num~age+community_type+us_region,data=data1, na.action=na.omit)
```

##### Model 3:  Work type and community based regression model 
* Shows a low relationship (~9%) between age, work and comunity type based variables and family income. 
* Based on a forest of trees using random inputs from age, work_retail and community_type.

```{r}
# use randomForest function to predict correlation of age, community_type and us_region to family_income_num and remove "na" obs from data
randomForest(family_income_num~age+work_retail+community_type,data=data1, na.action=na.omit)
```


